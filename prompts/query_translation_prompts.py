"""
LLM Prompts for Query Translation

This module contains structured prompts for the LLM to perform sophisticated
query translation from canonical schemas to customer-specific multi-table schemas.
"""


def get_relationship_discovery_prompt() -> str:
    """Prompt for discovering table relationships"""
    return """
You are a database expert specializing in schema analysis and relationship discovery.

## Your Task
Analyze the provided database schema to discover relationships between tables. Look for:

1. **Primary/Foreign Key Relationships**: Columns that likely reference other tables
2. **Logical Entity Relationships**: Tables that together represent a single business entity
3. **Naming Pattern Relationships**: Tables with similar naming patterns that might be related
4. **Data Type Relationships**: Columns with matching data types that could be related

## Analysis Guidelines
- Look for columns ending in "_id" that might reference other tables
- Identify tables that together form logical entities (like "contracts")
- Consider naming patterns (contract_headers, contract_status, contract_details)
- Analyze data types for potential relationships
- Consider business logic and domain knowledge

## Response Format
Provide a JSON array of relationships with the following structure:

```json
[
    {
        "table1": "contract_headers",
        "column1": "id",
        "table2": "contract_status_history",
        "column2": "contract_id",
        "relationship_type": "one_to_many",
        "confidence": 0.95,
        "reasoning": "contract_status_history.contract_id references contract_headers.id based on naming pattern and data types",
        "join_condition": "contract_headers.id = contract_status_history.contract_id",
        "is_primary_key": true,
        "is_foreign_key": false
    }
]
```

## Relationship Types (MUST use exactly these values)
- "one_to_one": Each record in table1 relates to exactly one record in table2
- "one_to_many": Each record in table1 relates to multiple records in table2
- "many_to_one": Multiple records in table1 relate to one record in table2
- "many_to_many": Records can have multiple relationships in both directions
- "logical_entity": Tables that together form a single business entity

CRITICAL: Use ONLY these exact relationship_type values. Do not create new types.

## Confidence Scoring
- 0.9-1.0: Very high confidence (explicit foreign key, clear naming pattern)
- 0.7-0.9: High confidence (strong naming pattern, matching data types)
- 0.5-0.7: Medium confidence (reasonable inference from naming/data types)
- 0.3-0.5: Low confidence (weak evidence, requires validation)
- 0.0-0.3: Very low confidence (speculative, likely incorrect)

Focus on relationships that would be needed to reconstruct logical entities like "contracts" from multiple tables.
"""


def get_join_strategy_prompt() -> str:
    """Prompt for generating JOIN strategies"""
    return """
You are a database performance expert specializing in JOIN optimization and query planning.

## Your Task
Analyze the query requirements and customer schema to determine the optimal JOIN strategy.

## Considerations
1. **Performance**: Which JOIN order minimizes data transfer and processing time?
2. **Selectivity**: Which tables should be filtered first to reduce JOIN size?
3. **Indexes**: What indexes would improve performance?
4. **Join Types**: When to use INNER vs LEFT JOIN?
5. **Data Volume**: Consider table sizes and expected result sets

## JOIN Strategy Guidelines
- Start with the most selective table (smallest result set after filtering)
- Use INNER JOIN when the relationship is required
- Use LEFT JOIN when the relationship is optional
- Consider filtering early to reduce JOIN complexity
- Optimize for the most common query patterns

## Response Format
Provide a JSON object with the following structure:

```json
{
    "primary_table": "contract_headers",
    "join_tables": [
        ["contract_status_history", "contract_headers.id = contract_status_history.contract_id", "INNER"],
        ["renewal_schedule", "contract_headers.id = renewal_schedule.contract_id", "LEFT"]
    ],
    "join_order": ["contract_headers", "contract_status_history", "renewal_schedule"],
    "confidence": 0.85,
    "reasoning": "Start with contract_headers as the primary table. Join status_history with INNER JOIN for required status data, then LEFT JOIN renewal_schedule for optional expiry data.",
    "performance_notes": [
        "Add index on contract_headers.id",
        "Add index on contract_status_history.contract_id",
        "Filter by status early to reduce JOIN size"
    ]
}
```

## Performance Optimization
- Consider table sizes and selectivity
- Suggest appropriate indexes
- Recommend filtering strategies
- Identify potential performance bottlenecks
- Suggest query execution optimizations
"""


def get_query_translation_prompt() -> str:
    """Prompt for translating queries with enhanced schema awareness"""
    return """
You are a SQL expert specializing in query translation across different database schemas.

## TARGET DATABASE: DuckDB
The translated SQL MUST be 100% compatible with DuckDB syntax.

## Your Task
Translate a canonical query into customer-specific DuckDB SQL using the provided schema and JOIN strategy.

## âš ï¸ CRITICAL REQUIREMENTS - SCHEMA VALIDATION âš ï¸
1. **MANDATORY COLUMN VERIFICATION**: Before writing ANY SQL, verify EVERY column exists in the target schema
2. **FORBIDDEN ACTIONS**: 
   - NEVER reference columns that don't exist (e.g., 'status' in awards table)
   - NEVER assume column names without checking the schema
   - NEVER use canonical field names directly without mapping
3. **REQUIRED PROCESS**:
   - Step 1: List all columns needed from the canonical query
   - Step 2: For EACH column, find the exact match in the target schema
   - Step 3: If no exact match, find semantic equivalent using actual schema columns
   - Step 4: Verify all mapped columns exist before writing SQL

## ðŸš¨ CRITICAL: UNIT CONVERSION REQUIRED ðŸš¨
**MANDATORY**: If target column contains values in millions (e.g., contract_value_usd_millions), you MUST convert all numeric values:
- WHERE value_amount > 1000000 â†’ WHERE contract_value_usd_millions > 1
- WHERE value_amount > 10000000 â†’ WHERE contract_value_usd_millions > 10  
- WHERE value_amount > 200000000 â†’ WHERE contract_value_usd_millions > 200
- WHERE value_amount BETWEEN 500000 AND 50000000 â†’ WHERE contract_value_usd_millions BETWEEN 0.5 AND 50

**FAILURE TO CONVERT UNITS WILL RESULT IN INCORRECT QUERIES!**

## SEMANTIC FIELD MAPPING RULES
When canonical fields don't exist, use these mapping strategies:
- **'status' field**: 
  - If no 'status' column exists, derive from date ranges (period_start, period_end)
  - Use action_type, award_type, or other categorical fields
  - Create CASE statements to simulate status logic
- **'contract_id' field**: 
  - Map to generated_unique_award_id, piid, or primary key
- **'value' field**: 
  - Map to current_total_value, obligated_amount, or monetary fields
  - **CRITICAL: Handle unit conversions automatically**
  - If target column is in millions (e.g., contract_value_usd_millions), convert values:
    - WHERE value_amount > 1000000 â†’ WHERE contract_value_usd_millions > 1
    - WHERE value_amount > 10000000 â†’ WHERE contract_value_usd_millions > 10
    - WHERE value_amount BETWEEN 500000 AND 50000000 â†’ WHERE contract_value_usd_millions BETWEEN 0.5 AND 50

## EXAMPLE TRANSLATION PROCESS

### Example 1: Status Field Mapping
Canonical: SELECT contract_id, status FROM contracts WHERE status = 'active'

Step 1: Required fields: contract_id, status
Step 2: Schema check for tenant_A awards table:
- contract_id â†’ generated_unique_award_id âœ“ (exists)
- status â†’ NOT FOUND âŒ (awards table has no 'status' column)
Step 3: Semantic mapping for 'status':
- Use period_start/period_end dates to determine if award is active
- Create CASE statement: active if current date between period_start and period_end
Step 4: Write SQL using only existing columns

### Example 2: Unit Conversion (CRITICAL)
Canonical: SELECT contract_id, value_amount FROM contracts WHERE value_amount > 10000000

Step 1: Required fields: contract_id, value_amount
Step 2: Schema check for tenant_D contracts table:
- contract_id â†’ contract_id âœ“ (exists)
- value_amount â†’ contract_value_usd_millions âœ“ (exists, but in millions!)
Step 3: Unit conversion required:
- Original: WHERE value_amount > 10000000 (10 million dollars)
- Converted: WHERE contract_value_usd_millions > 10 (10 million = 10 in millions column)
Step 4: Write SQL with converted values:
```sql
SELECT contract_id, contract_value_usd_millions AS value_amount
FROM contracts 
WHERE contract_value_usd_millions > 10
```

### Example 3: tenant_D Specific Unit Conversion
**For tenant_D contracts table with contract_value_usd_millions column:**

Canonical: WHERE value_amount > 200000000 (200 million dollars)
**MUST convert to:** WHERE contract_value_usd_millions > 200 (200 million = 200 in millions column)

Canonical: WHERE value_amount > 1000000 (1 million dollars)  
**MUST convert to:** WHERE contract_value_usd_millions > 1 (1 million = 1 in millions column)

Canonical: WHERE value_amount BETWEEN 500000 AND 50000000 (0.5M to 50M dollars)
**MUST convert to:** WHERE contract_value_usd_millions BETWEEN 0.5 AND 50 (0.5M to 50M in millions column)

## Translation Requirements
1. **Field Mapping**: Map canonical field names to actual customer column names
2. **Table Aliases**: Use clear, consistent table aliases for readability
3. **JOIN Syntax**: Use proper JOIN syntax with appropriate join types
4. **WHERE Conditions**: Adapt WHERE conditions to use available fields
5. **GROUP BY/ORDER BY**: Maintain clauses with correct table references
6. **Aggregations**: Preserve aggregation functions using available columns
7. **Semantic Equivalence**: Maintain the query's business intent even if exact fields don't exist

## Schema-Aware Adaptations
- If 'status = active' but no status field exists, use date logic: `period_end IS NULL OR period_end > CURRENT_DATE`
- If 'contract_id' doesn't exist, use the primary key or unique identifier from the schema
- If monetary fields have different names, map to the appropriate value column

## DuckDB-Specific Syntax Rules (CRITICAL)
1. **Lists/Arrays**: Use DuckDB list syntax [...] NOT ARRAY[...]
   - CORRECT: [value1, value2]
   - WRONG: ARRAY[value1, value2]
2. **List Functions**: DO NOT use PostgreSQL array functions like ARRAY_REMOVE
   - Use list_filter() or simple list literals instead
3. **Date Functions**: Use DuckDB date syntax
   - CURRENT_DATE (not NOW() for dates)
   - CAST('2025-01-01' AS DATE) for date literals
4. **Keep queries SIMPLE**: Avoid complex array operations when possible

## SQL Best Practices
- Use meaningful table aliases (a for awards, t for transactions, etc.)
- Add table prefixes to avoid column ambiguity
- Use proper JOIN conditions based on discovered relationships
- Maintain query logic and business semantics
- Ensure syntactically correct DuckDB SQL using only existing schema elements
- Optimize for readability and performance
- **AVOID complex array/list operations** - keep queries simple

## Response Format
Provide only the translated SQL query in DuckDB syntax, no explanations or additional text.

## Example Schema-Aware Translation
Canonical: SELECT contract_id, status FROM contracts WHERE status = 'active'

If schema has awards table with sample data showing:
- generated_unique_award_id: "CONT_AWD_N6871177F7668_9700_-NONE-_-NONE-"
- award_type: "DEFINITIVE CONTRACT" (not "active")
- period_start: "1977-06-01", period_end: "2025-09-30"

Correct translation using actual data patterns:
```sql
SELECT a.generated_unique_award_id AS contract_id, 
       CASE WHEN a.period_end IS NULL OR a.period_end > CURRENT_DATE THEN 'active' ELSE 'inactive' END AS status
FROM awards a
WHERE a.period_end IS NULL OR a.period_end > CURRENT_DATE
```

WRONG - Don't do this (uses non-existent values):
```sql
SELECT a.generated_unique_award_id AS contract_id, a.status
FROM awards a  
WHERE a.status = 'active'  -- 'active' doesn't exist in award_type sample data!
```

Focus on creating working SQL that uses only existing schema elements while preserving the original query's business intent.
"""


def get_logical_entity_discovery_prompt() -> str:
    """Prompt for discovering logical entities"""
    return """
You are a database expert specializing in logical entity modeling and schema normalization analysis.

## Your Task
Identify logical business entities that are split across multiple tables in the customer schema.

## Entity Types to Look For
1. **Contract Entity**: Tables that together represent a "contract" (headers, status, details, lifecycle, etc.)
2. **Party Entity**: Tables that together represent parties (buyers, suppliers, etc.)
3. **Transaction Entity**: Tables that together represent financial transactions
4. **Document Entity**: Tables that together represent documents and attachments
5. **Project Entity**: Tables that together represent projects or initiatives

## Analysis Guidelines
- Look for tables with similar naming patterns (contract_*, party_*, transaction_*)
- Identify tables that together contain all information about a business entity
- Consider functional dependencies and business logic
- Think about how a user would naturally query for complete entity information

## Response Format
Provide a JSON array of logical entities:

```json
[
    {
        "entity_name": "contract",
        "primary_table": "contract_headers",
        "related_tables": ["contract_status_history", "renewal_schedule", "contract_details"],
        "relationships": [
            {
                "table1": "contract_headers",
                "column1": "id",
                "table2": "contract_status_history",
                "column2": "contract_id",
                "relationship_type": "one_to_many"
            }
        ],
        "confidence": 0.90,
        "reasoning": "These tables together represent a complete contract entity with headers, status history, renewal information, and details"
    }
]
```

## Confidence Scoring
- 0.9-1.0: Very high confidence (clear business entity, obvious relationships)
- 0.7-0.9: High confidence (strong naming patterns, clear relationships)
- 0.5-0.7: Medium confidence (reasonable entity grouping)
- 0.3-0.5: Low confidence (weak evidence, requires validation)
- 0.0-0.3: Very low confidence (speculative grouping)

Focus on entities that would be commonly queried together in business applications.
"""


def get_query_complexity_analysis_prompt() -> str:
    """Prompt for analyzing query complexity"""
    return """
You are a database expert specializing in query complexity analysis and optimization.

## Your Task
Analyze the provided query to determine its complexity and translation requirements.

## Complexity Factors
1. **Table Count**: Number of tables involved
2. **JOIN Complexity**: Number and type of JOINs required
3. **Filter Complexity**: WHERE clause complexity and selectivity
4. **Aggregation Complexity**: GROUP BY, HAVING, and aggregation functions
5. **Subquery Complexity**: Presence and complexity of subqueries
6. **Sorting Complexity**: ORDER BY complexity

## Complexity Levels
- **SIMPLE**: Single table, no JOINs needed
- **MODERATE**: 2-3 table JOINs, basic filtering
- **COMPLEX**: 4+ table JOINs, complex filtering, aggregations
- **VERY_COMPLEX**: Multiple entities, subqueries, complex aggregations

## Analysis Guidelines
- Count the number of different tables that would be needed
- Assess the complexity of WHERE conditions
- Identify aggregation requirements
- Look for subqueries and nested logic
- Consider performance implications

## Response Format
Provide a JSON object with complexity analysis:

```json
{
    "complexity_level": "COMPLEX",
    "table_count": 3,
    "join_count": 2,
    "has_aggregations": true,
    "has_subqueries": false,
    "filter_complexity": "moderate",
    "performance_impact": "medium",
    "reasoning": "Query requires 3 tables with 2 JOINs and includes aggregations, making it complex",
    "optimization_suggestions": [
        "Add indexes on JOIN columns",
        "Consider filtering early",
        "Optimize aggregation performance"
    ]
}
```

Focus on providing actionable insights for query optimization and translation.
"""


def get_performance_optimization_prompt() -> str:
    """Prompt for performance optimization suggestions"""
    return """
You are a database performance expert specializing in query optimization and execution planning.

## Your Task
Analyze the translated query and JOIN strategy to provide performance optimization suggestions.

## Optimization Areas
1. **Indexing Strategy**: Suggest indexes for JOIN columns, WHERE clauses, and ORDER BY
2. **JOIN Optimization**: Optimize JOIN order and types
3. **Filtering Strategy**: Suggest early filtering to reduce data volume
4. **Aggregation Optimization**: Optimize GROUP BY and aggregation functions
5. **Query Structure**: Suggest query restructuring for better performance

## Performance Considerations
- **Data Volume**: Consider table sizes and expected result sets
- **Selectivity**: Identify highly selective filters
- **Index Usage**: Ensure indexes can be used effectively
- **JOIN Efficiency**: Optimize JOIN order and types
- **Memory Usage**: Consider memory requirements for large result sets

## Response Format
Provide a JSON object with optimization suggestions:

```json
{
    "index_suggestions": [
        "CREATE INDEX idx_contract_headers_id ON contract_headers(id)",
        "CREATE INDEX idx_status_history_contract_id ON contract_status_history(contract_id)",
        "CREATE INDEX idx_status_history_status ON contract_status_history(status)"
    ],
    "join_optimizations": [
        "Start with contract_headers as it's the most selective",
        "Use INNER JOIN for required relationships",
        "Use LEFT JOIN for optional relationships"
    ],
    "filter_optimizations": [
        "Filter by status early to reduce JOIN size",
        "Add WHERE conditions to reduce data volume",
        "Consider partitioning for large tables"
    ],
    "query_restructuring": [
        "Consider using EXISTS instead of IN for subqueries",
        "Use appropriate data types for comparisons",
        "Consider materialized views for complex aggregations"
    ],
    "performance_score": 0.75,
    "reasoning": "Query can be optimized with proper indexing and JOIN order"
}
```

Focus on providing practical, implementable optimization suggestions.
"""
