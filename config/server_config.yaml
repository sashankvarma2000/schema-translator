# Server Configuration
# This file defines server and application settings

server:
  web_dashboard:
    host: "0.0.0.0"
    port: 8080
    debug: true
  api_server:
    host: "0.0.0.0" 
    port: 8001
    debug: true
  base_url: "http://localhost"

# LLM Configuration
llm:
  provider: "openai"
  model: "gpt-5.2"
  temperature: 0.1
  max_tokens: 4000
  timeout: 30
  retry_attempts: 3

# Database Configuration
database:
  schemas_directory: "customer_schemas"
  canonical_schema: "canonical_schema_original.yaml"
  sample_data_directory: "customer_samples"

# Performance Settings
performance:
  cache_enabled: true
  cache_ttl: 3600  # 1 hour
  max_concurrent_requests: 10
  request_timeout: 30

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/schema_translator.log"
  max_file_size: "10MB"
  backup_count: 5

# Security Settings
security:
  api_key_required: true
  rate_limiting:
    enabled: true
    requests_per_minute: 60
  cors:
    enabled: true
    origins: ["http://localhost:8080", "http://127.0.0.1:8080"]
